version: "3.9"
services:
  # ðŸ”¹ MySQL para base de datos de  customer service
  mysql8:
    container_name: mysql8
    image: mysql:8
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: sasa
      MYSQL_DATABASE: db_cliente
    volumes:
      - data-mysql:/var/lib/mysql
    restart: always
    networks:
      - devsu
  # ðŸ”¹ Postgres para base datos de account service
  postgres14:
    container_name: postgres14
    image: postgres:14-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: sasa
      POSTGRES_DB: db_cuenta
    volumes:
      - data-postgres:/var/lib/postgresql/data
    restart: always
    networks:
      - devsu
  # ðŸ”¹ Mongo para base de datos de transactional service
  mongodb:
    container_name: mongodb
    image: mongo
    ports:
      - "27017:27017"
    environment:
      MONGODB_INITDB_ROOT_USERNAME: mongouser
      MONGODB_INITDB_ROOT_PASSWORD: mongopass
      MONGO_INITDB_DATABASE: db_movimiento
    volumes:
      - data-mongo:/data/db
    restart: always
    networks:
      - devsu

  # ðŸ”¹ Kafka para la publicacion y consumo de eventos, para los servicios account, customer and transaction
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"

      #listeners solo en docker
      #KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:29093
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      #KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      #KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      #KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Listeners: uno externo (localhost), uno interno (kafka)
      KAFKA_LISTENERS: PLAINTEXT://:9092,EXTERNAL://:29092,CONTROLLER://:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1


      CLUSTER_ID: "YjA0NDQyZjBjYjQzNDExN2"
    volumes:
      - data-kafka:/var/lib/kafka/data
    healthcheck:
      test: [ "CMD", "bash", "-c", "nc -z localhost 9092" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - devsu

  # ðŸ”¹ Servicio que crea los tÃ³picos y se destruy
  kafka-init-topics:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: [ "/bin/bash", "-c" ]
    command: >
      "
      kafka-topics --create --if-not-exists --topic customer-events --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092 &&
      kafka-topics --create --if-not-exists --topic account-events --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092 &&
      kafka-topics --create --if-not-exists --topic transaction-events --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092 &&
      echo 'âœ… TÃ³picos creados correctamente'
      "
    restart: "on-failure"
    networks:
      - devsu


  # ðŸ”¹ Servicio para monitoreo, creaciÃ³n y modificaciÃ³n de tÃ³picos
  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
    depends_on:
      - kafka
    restart: always
    networks:
      - devsu


volumes:
  data-mysql:
    name: data-mysql
  data-postgres:
    name: data-postgres
  data-mongo:
    name: data-mongo
  data-kafka:
    name: data-kafka


networks:
  devsu:
    name: devsu
    driver: bridge